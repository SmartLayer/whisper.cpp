# Hardware Acceleration Performance Comparison

## Test System 1: Intel Arc (Previous)
- **CPU**: Intel Core Ultra 7 258V (Lunar Lake)
- **GPU**: Intel Arc Graphics 130V/140V (integrated)
- **Model**: ggml-medium.en.bin
- **Test File**: samples/jfk.wav (11 seconds, 176,000 samples)
- **Threads**: 4
- **Test Date**: 9 October 2025
- **Verification**: Results verified reproducible with same audio file (CPU encode: 12,635.75 ms vs documented 12,537 ms - 0.8% variance)

## Test System 2: NVIDIA RTX 2070 SUPER (Current)
- **CPU**: AMD Ryzen 7 5800X (8-core, 16-thread)
- **GPU**: NVIDIA GeForce RTX 2070 SUPER (8GB VRAM, Compute Capability 7.5)
- **CUDA**: Version 12.2.140
- **Test File**: samples/jfk.wav (11 seconds, 176,000 samples)
- **Threads**: 4
- **Test Date**: 9 October 2025

## Results Summary

### System 1: Intel Arc (Previous System)

#### CPU Only (Baseline - Before GPU Acceleration)
```
encode time = 12,536 ms
total time  = ~20,000 ms
```

#### Vulkan GPU Acceleration ‚úÖ **WINNER**
```
whisper_backend_init_gpu: using Vulkan0 backend
encode time = 4,890 ms  (2.56x faster than CPU)
decode time = 137 ms
batchd time = 6,923 ms
total time  = 12,856 ms
```

**Status**: ‚úÖ Working perfectly
**Speedup**: 2.56x faster encoding vs CPU-only

### System 2: NVIDIA RTX 2070 SUPER (Current System)

#### CPU Only (Optimized Baseline)
```
# Tiny Model
encode time = 474 ms
total time  = 557 ms

# Small Model  
encode time = 3,237 ms
total time  = 3,499 ms
```

**Status**: ‚úÖ Excellent CPU performance (26.4x faster than Intel system!)

#### CUDA GPU Acceleration üöÄ **MASSIVE WINNER**
```
# Tiny Model
whisper_backend_init_gpu: using CUDA0 backend
encode time = 39.72 ms  (11.9x faster than CPU!)
total time  = 223 ms

# Small Model
whisper_backend_init_gpu: using CUDA0 backend  
encode time = 66.38 ms  (48.8x faster than CPU!)
total time  = 264 ms
```

**Status**: ‚úÖ Working perfectly with RTX 2070 SUPER
**Speedup**: 11.9x-48.8x faster encoding vs CPU-only
**GPU**: NVIDIA GeForce RTX 2070 SUPER (8GB VRAM, Compute Capability 7.5)

### SYCL (Intel oneAPI) ‚ùå **WORKS BUT VERY SLOW**

**SYCL with OpenCL Backend:**
```
whisper_backend_init_gpu: using SYCL0 backend
encode time = 8,428 ms  (1.7x SLOWER than CPU!)
total time  = 33,894 ms (2.6x slower than Vulkan!)
```

**SYCL with Level Zero Backend:**
```
whisper_backend_init_gpu: using SYCL0 backend
encode time = 10,110 ms (1.9x SLOWER than CPU!)
total time  = 33,447 ms (2.6x slower than Vulkan!)
```

**Status**: ‚úÖ Works after installing GPU drivers, but terrible performance
**Speedup**: ‚ùå 0.59x (actually **1.7-1.9x slower** than CPU-only!)

**Required Packages**:
```bash
# For OpenCL backend
sudo apt-get install intel-opencl-icd libze-intel-gpu1

# For Level Zero backend (even worse performance!)
wget https://github.com/oneapi-src/level-zero/releases/download/v1.24.2/level-zero_1.24.2+u22.04_amd64.deb
sudo dpkg -i level-zero_1.24.2+u22.04_amd64.deb
```

**Why SYCL is Slow**:
- Both OpenCL and Level Zero backends perform poorly for this workload
- Surprisingly, Level Zero (20% slower) performs worse than OpenCL
- Excessive overhead in batch decode operations (21-22s vs 7s for Vulkan)
- SYCL runtime adds significant latency
- whisper.cpp SYCL backend not well optimized for integrated Arc GPUs

## Recommendation

### For Intel Arc Systems
**Use Vulkan acceleration** - it provides excellent performance (2.56x speedup) and works reliably with the Intel Arc 130V/140V iGPU.

### For NVIDIA RTX Systems  
**Use CUDA acceleration** - it provides MASSIVE performance improvements (11.9x-48.8x speedup) and works perfectly with NVIDIA GPUs.

### For Your Voice Typing Script

**Current System (RTX 2070 SUPER)**: Use the CUDA-accelerated binary at `./build-cuda/bin/whisper-cli` for maximum performance!

**Previous System (Intel Arc)**: Use the Vulkan-accelerated binary at `./build/bin/whisper-cli` for good performance.

## Build Information

### CUDA (Recommended for NVIDIA GPUs)
```bash
# Required packages
sudo apt install nvidia-cuda-toolkit

# Build command
cmake -B build-cuda -DGGML_CUDA=ON -DCMAKE_BUILD_TYPE=Release
cmake --build build-cuda -j --config Release

# Binary location
./build-cuda/bin/whisper-cli
```

### Vulkan (Recommended for Intel Arc)
```bash
# Required packages
sudo apt-get install libvulkan-dev glslang-tools spirv-tools libshaderc-dev glslc

# Build command
cmake -B build -DGGML_VULKAN=1
cmake --build build -j --config Release

# Binary location
./build/bin/whisper-cli
```

**Note**: Required a fix to `src/whisper.cpp` to support integrated GPUs (iGPU). The fix allows whisper.cpp to detect `GGML_BACKEND_DEVICE_TYPE_IGPU` in addition to `GGML_BACKEND_DEVICE_TYPE_GPU`.

### SYCL (Not Recommended for this Hardware)
```bash
# Installation size: ~5.7 GB (oneAPI DPC++ + MKL)
sudo apt-get install intel-oneapi-compiler-dpcpp-cpp intel-oneapi-mkl-devel

# Build command
source /opt/intel/oneapi/setvars.sh
cmake -B build-sycl -DGGML_SYCL=ON -DCMAKE_C_COMPILER=icx -DCMAKE_CXX_COMPILER=icpx
cmake --build build-sycl -j --config Release

# Status: Compiles but crashes at runtime
```

## Performance Metrics Detail

### Vulkan GPU - Detailed Timings
| Operation | Time (ms) | Notes |
|-----------|-----------|-------|
| Model Load | 713 | One-time cost |
| Mel Spectrogram | 15 | Audio preprocessing |
| Encode | **4,890** | Main computation (GPU accelerated) |
| Decode | 137 | Language model decode |
| Batch Decode | 6,923 | Batch processing |
| **Total** | **12,856** | End-to-end |

### CPU Only - Detailed Timings
| Operation | Time (ms) | Notes |
|-----------|-----------|-------|
| Model Load | 729 | One-time cost |
| Mel Spectrogram | 15 | Audio preprocessing |
| Encode | **12,537** | Main computation (CPU only) |
| Decode | 35 | Language model decode |
| Batch Decode | 3,617 | Batch processing |
| **Total** | **~20,000** | End-to-end |

## Real-World Impact

For 11 seconds of audio:
- **CPU Only**: ~20 seconds processing time (1.8x slower than real-time)
- **Vulkan GPU**: ~13 seconds processing time (1.2x slower than real-time)

For your voice typing use case, this means:
- **Less waiting** between speaking and seeing text appear
- **Better responsiveness** for real-time dictation
- **No additional overhead** - voice typing script already uses the accelerated binary

## Conclusion

**Vulkan** is the overwhelming winner for your Intel Arc 130V/140V integrated GPU. It provides substantial performance improvements (2.56x faster) with excellent stability and uses the standard Mesa Vulkan drivers that Ubuntu already provides.

**SYCL** technically works after installing Intel OpenCL/Level Zero drivers (`intel-opencl-icd` and `libze-intel-gpu1`), but delivers terrible performance - actually slower than CPU-only mode. The OpenCL backend is poorly optimized for integrated Arc GPUs compared to Vulkan's native support.

## Technical Notes

### Vulkan Driver Information
```
Device: Intel(R) Graphics (LNL) (Intel open-source Mesa driver)
Type: Integrated GPU (uma: 1)
FP16 Support: Yes
Matrix Cores: KHR_coopmat
Driver: libvulkan_intel.so
```

### Code Fix Applied
Modified `src/whisper.cpp` line 1292 to detect integrated GPUs:
```cpp
// Support both discrete GPUs and integrated GPUs (iGPU)
if (dev_type == GGML_BACKEND_DEVICE_TYPE_GPU || dev_type == GGML_BACKEND_DEVICE_TYPE_IGPU) {
```

This fix should be submitted as a patch to the upstream whisper.cpp repository.

